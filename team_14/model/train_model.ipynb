{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hack4ukraine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "O3mJDBDnepPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from datasets import load_metric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (AutoTokenizer, AutoModel, TrainingArguments, \n",
        "                          Trainer, BertForSequenceClassification)\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('drive/MyDrive/hack4ukraine')\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "zH6RXjqle7kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de163142-2388-45eb-d27a-651b80e684d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset compatible with BERT transformer from hugging face library\n",
        "    \"\"\"\n",
        "    def __init__(self, vector_len: int = 130) -> None:\n",
        "        df = pd.read_csv('lemmatized.csv')\n",
        "\n",
        "        # Oversampling of class with less recores\n",
        "        ones_count = df['label'].sum()\n",
        "        zeros_count = df.shape[0] - ones_count\n",
        "        ones_Xs = df.loc[df['label'] == 1]\n",
        "        t = ones_count\n",
        "        while t < zeros_count:\n",
        "          df = pd.concat([df, ones_Xs])\n",
        "          t += ones_count\n",
        "        df = df.sample(frac=1, replace=False)\n",
        "\n",
        "        # Tokenize\n",
        "        tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base', \n",
        "                                                  normalize=True)\n",
        "        self.texts = df['text']\n",
        "        self.texts = tokenizer(self.texts.tolist(),\n",
        "                               padding='max_length',\n",
        "                               max_length=vector_len,\n",
        "                               truncation=True)\n",
        "\n",
        "        # Process tokenized texts\n",
        "        self.ids = self.texts['input_ids']\n",
        "        self.token_type_ids = self.texts['token_type_ids']\n",
        "        self.attention_mask = self.texts['attention_mask']\n",
        "        \n",
        "        # Save labels\n",
        "        self.labels = df['label']\n",
        "        self.labels = torch.Tensor(self.labels.values)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "    def get_batch_labels(self, idx: slice) -> torch.Tensor:\n",
        "        return self.labels[idx]\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        return {'input_ids': self.ids[idx],\n",
        "                'token_type_ids': self.token_type_ids[idx],\n",
        "                'attention_mask': self.attention_mask[idx]}\n",
        "\n",
        "    def __getitem__(self, idx: slice):\n",
        "        item = self.get_batch_texts(idx)\n",
        "        item['labels'] = self.get_batch_labels(idx).long()\n",
        "        return item"
      ],
      "metadata": {
        "id": "WfnGK8OsjmRK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = BertDataset()"
      ],
      "metadata": {
        "id": "esSq94mZjbrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices, test_indices = train_test_split(list(range(len(dataset))), test_size = .4)\n",
        "test_indices, val_indices = train_test_split(test_indices, test_size = .5)\n",
        "\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 32)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = 32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32)"
      ],
      "metadata": {
        "id": "UZB8afxQkpzh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = load_metric(\"accuracy\")\n",
        "recall = load_metric('recall')\n",
        "precision = load_metric('precision')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy.compute(predictions=predictions, references=labels)['accuracy'],\n",
        "            'recall': recall.compute(predictions=predictions, references=labels)['recall'],\n",
        "            'precision': precision.compute(predictions=predictions, references=labels)['precision']}\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('vinai/bertweet-base', \n",
        "                                                      num_labels = 2)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "training_args = TrainingArguments(\"bert_trainer\", \n",
        "                                  num_train_epochs = 7,\n",
        "                                  per_device_train_batch_size = 32,\n",
        "                                  per_device_eval_batch_size = 32,\n",
        "                                  evaluation_strategy = 'steps',\n",
        "                                  eval_steps = 40,\n",
        "                                  logging_steps = 40,\n",
        "                                  )"
      ],
      "metadata": {
        "id": "MFtq1_9Fk5u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, \n",
        "                  args = training_args, \n",
        "                  train_dataset = train_dataset, \n",
        "                  eval_dataset = val_dataset, \n",
        "                  compute_metrics = compute_metrics)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "id": "h_nH9D9MlqVM",
        "outputId": "8326b0a4-99aa-41dc-b945-0c3407ecde26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1363\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 301\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='301' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [301/301 04:01, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.753000</td>\n",
              "      <td>0.701349</td>\n",
              "      <td>0.468132</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.468132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.700200</td>\n",
              "      <td>0.695721</td>\n",
              "      <td>0.468132</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.468132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.699500</td>\n",
              "      <td>0.671547</td>\n",
              "      <td>0.569231</td>\n",
              "      <td>0.708920</td>\n",
              "      <td>0.529825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>1.366030</td>\n",
              "      <td>0.569231</td>\n",
              "      <td>0.948357</td>\n",
              "      <td>0.521964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.351500</td>\n",
              "      <td>0.595161</td>\n",
              "      <td>0.745055</td>\n",
              "      <td>0.755869</td>\n",
              "      <td>0.715556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.271800</td>\n",
              "      <td>0.620995</td>\n",
              "      <td>0.797802</td>\n",
              "      <td>0.755869</td>\n",
              "      <td>0.800995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.216800</td>\n",
              "      <td>0.650634</td>\n",
              "      <td>0.764835</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.699248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 455\n",
            "  Batch size = 32\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=301, training_loss=0.4813436146986445, metrics={'train_runtime': 242.2308, 'train_samples_per_second': 39.388, 'train_steps_per_second': 1.243, 'total_flos': 637391670497400.0, 'train_loss': 0.4813436146986445, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cpu')\n",
        "torch.save(model, 'model.pt')"
      ],
      "metadata": {
        "id": "UBuLowSlCXDd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('vinai/bertweet-base', \n",
        "                                           normalize=True)\n",
        "torch.save(tokenizer, 'preprocessing.pt')"
      ],
      "metadata": {
        "id": "A9ixOldXyuSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}